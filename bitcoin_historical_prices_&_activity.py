# -*- coding: utf-8 -*-
"""Bitcoin_Historical_Prices_&_Activity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P38QNKYZmoBztq0VT-9k_KrXZx5V0yhQ
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow

!pip install --upgrade tensorflow

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
from IPython.display import display
from sklearn.model_selection import train_test_split
import seaborn as sns

"""Dataset Preparation"""

# Load the dataset
column_names = ['Start', 'End', 'Open','High','Low', 'Close','Volume','Market Cap']
features = pd.read_csv('/content/drive/MyDrive/bitcoin_2010-07-27_2024-04-25.csv', names=column_names)

# Data cleaning
#features = features.drop(0)
features.drop(features.index[0], inplace=True)  # Drops the first row
features.reset_index(drop=True, inplace=True)
features.head(5)

# Check for missing values
missing_values = features.isnull().sum()
print("Missing values in each column:")
print(missing_values)

# Setting up the style
sns.set(style="whitegrid")

# Load your dataset here
# Adjust the path as needed
data = pd.read_csv('/content/drive/MyDrive/bitcoin_2010-07-27_2024-04-25.csv')
data['Start'] = pd.to_datetime(data['Start'])  # Ensure 'Start' is datetime
data = data[data['Start'].dt.year == 2024]  # Filter data for 2024

# Plotting Time Series of Prices
plt.figure(figsize=(14, 6))
plt.plot(data['Start'], data['Open'], label='Open')
plt.plot(data['Start'], data['Close'], label='Close')
plt.plot(data['Start'], data['High'], label='High')
plt.plot(data['Start'], data['Low'], label='Low')
plt.title('Time Series of Bitcoin Prices')
plt.xlabel('Date')
plt.ylabel('Price in USD')
plt.legend()
plt.show()

# Plotting Volume Traded Over Time
plt.figure(figsize=(14, 6))
plt.plot(data['Start'], data['Volume'], color='purple')
plt.title('Volume Traded Over Time')
plt.xlabel('Date')
plt.ylabel('Volume Traded')
plt.show()

# Scatter Plot of Market Cap vs. Volume
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Volume', y='Market Cap', data=data, color='red')
plt.title('Market Cap vs. Volume Traded')
plt.xlabel('Volume Traded')
plt.ylabel('Market Cap')
plt.show()

# Histograms of Prices and Volume
plt.figure(figsize=(14, 6))
sns.histplot(data[['Open', 'Close', 'High', 'Low']], kde=True)
plt.title('Distribution of Prices')
plt.xlabel('Price in USD')
plt.show()

plt.figure(figsize=(14, 6))
sns.histplot(data['Volume'], color='green', kde=True)
plt.title('Distribution of Volume Traded')
plt.xlabel('Volume Traded')
plt.show()

"""Data Preprocessing"""

# Perform Basic Statistical Analysis
# Showing basic statistics like mean, median, mode, standard deviation, and variance
print("\nBasic Statistical Analysis:")
print("Mean Values:")
print(data.mean(numeric_only=True))  # Mean of all numeric columns
print("\nMedian Values:")
print(data.median(numeric_only=True))  # Median of all numeric columns
print("\nMode Values:")
print(data.mode().iloc[0])  # Mode of all columns
print("\nStandard Deviation:")
print(data.std(numeric_only=True))  # Standard deviation of all numeric columns
print("\nVariance:")
print(data.var(numeric_only=True))  # Variance of all numeric columns

# Ensure we exclude non-numeric columns explicitly if they exist
numeric_data = data.select_dtypes(include=['float64', 'int64'])

# Check what columns are being included in the correlation matrix
print("Columns included in the correlation matrix:", numeric_data.columns)

# Calculate and print the correlation matrix
print("\nCorrelation Matrix:")
print(numeric_data.corr())

# Set the date as the index
data.set_index('Start', inplace=True)

# Trend Analysis
plt.figure(figsize=(14, 7))
plt.plot(data['Close'], label='Close Price')
plt.title('Bitcoin Close Price Trend')
plt.xlabel('Date')
plt.ylabel('Close Price (USD)')
plt.legend()
plt.show()

# Volatility Analysis
data['Daily Returns'] = data['Close'].pct_change()
data['Volatility'] = data['Daily Returns'].rolling(window=30).std() * np.sqrt(30)

plt.figure(figsize=(14, 7))
plt.plot(data['Volatility'], label='Volatility')
plt.title('Bitcoin Price Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.legend()
plt.show()

# Display the shape of the dataset
print("Dataset has", data.shape[0], "rows and", data.shape[1], "columns.")

# Importing necessary libraries
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Normalize the data using MinMaxScaler
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))

# Split the data into training and testing sets with 20% allocated to testing
train_data, test_data = train_test_split(scaled_data, test_size=0.2, random_state=42)

# Define a function to create sequences for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:(i + seq_length)])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

# Define sequence length (number of time steps)
seq_length = 10

# Create sequences for training and testing sets
X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)

# Reshape the data for LSTM model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Print the shapes of training and testing sets
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""Model Development"""

from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

#Define the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# Summary of the model
model.summary()

# Plot training and validation loss
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

"""Model Evaluation"""

train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Assuming your model has been trained and is named 'model'
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Evaluate the model
train_score = model.evaluate(X_train, y_train, verbose=0)
test_score = model.evaluate(X_test, y_test, verbose=0)

print("Train Loss:", train_score)
print("Test Loss:", test_score)

# Plot predictions vs actual values
plt.figure(figsize=(12, 6))

# Plot training data
plt.plot(np.arange(len(y_train)), y_train, label='Actual Train', color='blue')
plt.plot(np.arange(len(train_predictions)), train_predictions, label='Predicted Train', linestyle='dashed', color='orange')

# Plot testing data
plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, label='Actual Test', color='green')
plt.plot(np.arange(len(y_train), len(y_train) + len(test_predictions)), test_predictions, label='Predicted Test', linestyle='dashed', color='red')

plt.title('Bitcoin Price Prediction')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Assuming y_true and y_pred are defined
y_true = y_test  # Your actual values
y_pred = test_predictions  # Your predicted values from the model

# Calculate Mean Absolute Error
mae = mean_absolute_error(y_true, y_pred)
print("Mean Absolute Error (MAE):", mae)

# Calculate Root Mean Square Error
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
print("Mean Squared Error (MSE):", mse)
print("Root Mean Square Error (RMSE):", rmse)

"""Visualization of Model Predictions and Error Analysis"""

# Generate predictions
predictions = model.predict(X_test)

# Plotting Predictions vs Actual Prices
plt.figure(figsize=(10, 5))
plt.plot(y_test, label='Actual Prices', color='blue')
plt.plot(predictions, label='Predicted Prices', color='red', linestyle='--')
plt.title('Comparison of Actual and Predicted Bitcoin Prices')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

# Error Analysis - Plotting prediction errors over time
errors = predictions.flatten() - y_test.flatten()
plt.figure(figsize=(10, 5))
plt.plot(errors, color='purple')
plt.title('Prediction Errors Over Time')
plt.xlabel('Time')
plt.ylabel('Error')
plt.axhline(y=0, color='black', linestyle='--')  # Line at 0 error
plt.show()

# Optionally, visualize error distribution
plt.figure(figsize=(6, 4))
plt.hist(errors, bins=30, color='green', alpha=0.7)
plt.title('Distribution of Prediction Errors')
plt.xlabel('Error')
plt.ylabel('Frequency')
plt.show()